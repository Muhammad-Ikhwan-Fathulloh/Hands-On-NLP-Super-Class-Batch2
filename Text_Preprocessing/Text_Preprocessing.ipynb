{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-GK1zogmYAp"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('indonesian'))\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMMrb9FFobgw",
        "outputId": "64795cdb-9891-44e4-a3d0-a86c42bf0fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Teks contoh\n",
        "text = \"Saya belajar Natural Language Processing di rumah.\""
      ],
      "metadata": {
        "id": "7AYeqpkHo2Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text.lower())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jwnU53apZ8I",
        "outputId": "b1bef096-62e9-4bcc-a014-4a7704666d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saya belajar natural language processing di rumah.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenisasi\n",
        "tokens = word_tokenize(text.lower())  # Mengubah teks ke huruf kecil\n",
        "print(\"Token:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENAGagEpo97K",
        "outputId": "3d1bf91a-2a3e-4d15-ac81-38c494c84751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: ['saya', 'belajar', 'natural', 'language', 'processing', 'di', 'rumah', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghapus Stopwords\n",
        "tokens = [word for word in tokens if word not in stop_words]\n",
        "print(\"Tanpa Stopwords:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTqrko1Epzwr",
        "outputId": "9a18be8e-c64a-4f81-ee36-4742ce8262c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tanpa Stopwords: ['belajar', 'natural', 'language', 'processing', 'rumah', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "stemmed = [stemmer.stem(word) for word in tokens]\n",
        "print(\"Hasil Stemming:\", stemmed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNm3sZXQqB33",
        "outputId": "f6f198d1-0f3e-4058-8e2a-7cdc58bf7b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil Stemming: ['belajar', 'natur', 'languag', 'process', 'rumah', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "lemmatized = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "print(\"Hasil Lemmatization:\", lemmatized)"
      ],
      "metadata": {
        "id": "3CQ95RlOrglk",
        "outputId": "318e0fc1-ace6-4527-d09e-615bfdce5e38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil Lemmatization: ['belajar', 'natural', 'language', 'processing', 'rumah', '.']\n"
          ]
        }
      ]
    }
  ]
}