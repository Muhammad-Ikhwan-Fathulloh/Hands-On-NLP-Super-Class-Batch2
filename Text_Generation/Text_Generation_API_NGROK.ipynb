{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs5p0Vri5qlI",
        "outputId": "483ba1d1-a643-4917-cd71-8c1421ff2f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.9.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m221.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, pyngrok, starlette, fastapi\n",
            "Successfully installed fastapi-0.115.5 pyngrok-7.2.1 starlette-0.41.3 uvicorn-0.32.1\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi uvicorn pyngrok pydantic transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library tambahan jika belum ada\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
        "from pyngrok import ngrok\n",
        "import torch\n",
        "import os\n",
        "import uvicorn\n",
        "import threading"
      ],
      "metadata": {
        "id": "qF2fiNt-5xBb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnDRlpEd55cL",
        "outputId": "289813b5-0189-4056-9119-e7c1e1a1e9e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path ke model di Google Drive\n",
        "model_dir = \"/content/drive/My Drive/mentoring/Kelas-NLP/models/text-gen\"\n",
        "\n",
        "# Initialize the device\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# Load the model and tokenizer from the Google Drive directory\n",
        "model = AutoModelForCausalLM.from_pretrained(model_dir)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "\n",
        "# Create the pipeline\n",
        "# pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=device)\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    top_k=50,  # Memfilter kandidat output\n",
        "    top_p=0.9,  # Sampling dengan probabilitas kumulatif\n",
        "    temperature=0.8  # Mengontrol keacakan\n",
        ")\n"
      ],
      "metadata": {
        "id": "sEF9Ac5f5-UW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FastAPI app\n",
        "app = FastAPI(title=\"Text Generation Model Serving\")\n",
        "\n",
        "# Request body schema\n",
        "class TextGenerationRequest(BaseModel):\n",
        "    input_text: str\n",
        "    num_return_sequences: int = 1\n",
        "\n",
        "# Response body schema\n",
        "class TextGenerationResponse(BaseModel):\n",
        "    generated_text: str\n",
        "\n",
        "@app.post(\"/generate\", response_model=TextGenerationResponse)\n",
        "def generate_text(request: TextGenerationRequest):\n",
        "    \"\"\"\n",
        "    Generate text based on the input prompt.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Generate text\n",
        "        results = pipe(request.input_text, num_return_sequences=request.num_return_sequences)\n",
        "        # Return the first generated sequence\n",
        "        return TextGenerationResponse(generated_text=results[0][\"generated_text\"])\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Text generation failed: {str(e)}\")\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"message\": \"Welcome to the Text Generation API!\"}"
      ],
      "metadata": {
        "id": "AOVpbF1d6Ah8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ngrok config add-authtoken YOUR_NGROK_AUTHTOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt2cR6_T6XPD",
        "outputId": "2173d9c9-57c9-43cc-a8e6-07026c860681"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to run FastAPI server\n",
        "def run_app():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "# Start ngrok and FastAPI server\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print(f\"Public URL: {ngrok_tunnel.public_url}\")\n",
        "\n",
        "# Run FastAPI in a thread\n",
        "thread = threading.Thread(target=run_app)\n",
        "thread.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VjocVjf6YKF",
        "outputId": "404ef275-95c3-4d90-cf23-847d4cbc461e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://3e3f-34-23-185-71.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "NGROK_URL = \"https://3e3f-34-23-185-71.ngrok-free.app\"\n",
        "\n",
        "url = f\"{NGROK_URL}/generate\"\n",
        "\n",
        "data = {\n",
        "    \"input_text\": \"Hello, how are you?\",\n",
        "    \"num_return_sequences\": 2\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=data)\n",
        "\n",
        "print(response.json())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjkXuYJ27gkv",
        "outputId": "b36becc2-c1e0-40f7-f16f-e8226e0f4fa8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     34.23.185.71:0 - \"POST /generate HTTP/1.1\" 200 OK\n",
            "{'generated_text': 'Hello, how are you?\\n    \"\"\"\\n    return to_sql(\\n        tbl,\\n        if_exists=\\'append\\',\\n        index_col=index_col,\\n        chunksize=chunksize,\\n        dtype={\\n            \\'names\\': [\\n                (name,'}\n"
          ]
        }
      ]
    }
  ]
}