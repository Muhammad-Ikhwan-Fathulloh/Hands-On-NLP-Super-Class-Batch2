{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "923bcc262b84445a94aa92f264df5147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d1d60474f3f40bba9e944b83671f1f4",
              "IPY_MODEL_b78e8f4efa7446e2981df58ae6cb67c8",
              "IPY_MODEL_b2cbcbdaa8254537a752d061f9ab697b"
            ],
            "layout": "IPY_MODEL_d7ea54bd42f944faa93887c72d6ddcf0"
          }
        },
        "3d1d60474f3f40bba9e944b83671f1f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbdf6e1e65fd4fd092626aef9d4d9209",
            "placeholder": "​",
            "style": "IPY_MODEL_cfd1ff32d0b040019a5ff8a7e130688f",
            "value": "unsloth.Q4_K_M.gguf: 100%"
          }
        },
        "b78e8f4efa7446e2981df58ae6cb67c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d811b8bdf944bf9a13f45312df1fd2d",
            "max": 4920734080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8070dbfef76e4caea8862d9b00409dd1",
            "value": 4920734080
          }
        },
        "b2cbcbdaa8254537a752d061f9ab697b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89c1f0501d6b4a138516820c5f7a6cc9",
            "placeholder": "​",
            "style": "IPY_MODEL_992ef9300b164462b9605379298f81be",
            "value": " 4.92G/4.92G [02:00&lt;00:00, 42.3MB/s]"
          }
        },
        "d7ea54bd42f944faa93887c72d6ddcf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbdf6e1e65fd4fd092626aef9d4d9209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd1ff32d0b040019a5ff8a7e130688f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d811b8bdf944bf9a13f45312df1fd2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8070dbfef76e4caea8862d9b00409dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89c1f0501d6b4a138516820c5f7a6cc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "992ef9300b164462b9605379298f81be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDRGngUxNjDk",
        "outputId": "c3b2b4b5-78ae-4758-e4a6-a75e455a309f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.3.2.tar.gz (65.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.26.4)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.2-cp310-cp310-linux_x86_64.whl size=3410021 sha256=fe698e477520d33972e856a00373f2eec1bb9fc1bb2e7d31d3ca935658531e28\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/1c/f0/6c1ed6032d5827dea28df8a8df860d90ca1bcd7b3fa455f5e1\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.2\n"
          ]
        }
      ],
      "source": [
        "# Installasi Library yang Dibutuhkan\n",
        "!pip install huggingface_hub\n",
        "!pip install llama-cpp-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library\n",
        "from huggingface_hub import hf_hub_download\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path Google Drive untuk menyimpan model\n",
        "drive_model_dir = \"/content/drive/MyDrive/llama_model\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TTKoqhFNrbj",
        "outputId": "4d7c1a23-d98e-44c7-cafd-9473609f1f23"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download model dari Hugging Face\n",
        "def download_model(repo_id, filename, save_path):\n",
        "    print(\"Downloading model...\")\n",
        "    downloaded_file = hf_hub_download(\n",
        "        repo_id=repo_id,\n",
        "        filename=filename,\n",
        "        cache_dir=save_path\n",
        "    )\n",
        "    print(\"Model downloaded to:\", downloaded_file)\n",
        "    return downloaded_file\n",
        "\n",
        "# Simpan model ke Google Drive\n",
        "def save_to_drive(local_path, drive_path):\n",
        "    shutil.copy(local_path, drive_path)\n",
        "    print(f\"Model saved to Google Drive at: {drive_path}\")\n",
        "\n",
        "# Konfigurasi model\n",
        "repo_id = \"rubythalib33/llama3_1_8b_finetuned_bahasa_indonesia\"\n",
        "filename = \"unsloth.Q4_K_M.gguf\"\n",
        "\n",
        "# Unduh model ke Colab dan simpan ke Drive\n",
        "local_path = download_model(repo_id, filename, \"/content\")\n",
        "save_to_drive(local_path, f\"{drive_model_dir}/{filename}\")"
      ],
      "metadata": {
        "id": "qosjtPvpOFZS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "923bcc262b84445a94aa92f264df5147",
            "3d1d60474f3f40bba9e944b83671f1f4",
            "b78e8f4efa7446e2981df58ae6cb67c8",
            "b2cbcbdaa8254537a752d061f9ab697b",
            "d7ea54bd42f944faa93887c72d6ddcf0",
            "dbdf6e1e65fd4fd092626aef9d4d9209",
            "cfd1ff32d0b040019a5ff8a7e130688f",
            "5d811b8bdf944bf9a13f45312df1fd2d",
            "8070dbfef76e4caea8862d9b00409dd1",
            "89c1f0501d6b4a138516820c5f7a6cc9",
            "992ef9300b164462b9605379298f81be"
          ]
        },
        "outputId": "7109de07-2716-4881-ded6-c9709cfeeff2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.Q4_K_M.gguf:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "923bcc262b84445a94aa92f264df5147"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model downloaded to: /content/models--rubythalib33--llama3_1_8b_finetuned_bahasa_indonesia/snapshots/2f118fe76cf2dd5ebaba86fcebe460d99c2363d7/unsloth.Q4_K_M.gguf\n",
            "Model saved to Google Drive at: /content/drive/MyDrive/llama_model/unsloth.Q4_K_M.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "# Path model yang telah disalin ke Google Drive\n",
        "model_path = \"/content/drive/MyDrive/llama_model/unsloth.Q4_K_M.gguf\"\n",
        "\n",
        "# Memuat model dari Google Drive\n",
        "llm = Llama(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkw8k0sxT-Nr",
        "outputId": "002267cd-364a-4f2f-d385-e6405bf001fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 27 key-value pairs and 292 tensors from /content/drive/MyDrive/llama_model/unsloth.Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Meta Llama 3.1 8b Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = meta-llama-3.1\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 8B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128001\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128004\n",
            "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   66 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
            "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "llm_load_vocab: special tokens cache size = 256\n",
            "llm_load_vocab: token to piece cache size = 0.7999 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = BPE\n",
            "llm_load_print_meta: n_vocab          = 128256\n",
            "llm_load_print_meta: n_merges         = 280147\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 131072\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 500000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 131072\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 8.03 B\n",
            "llm_load_print_meta: model size       = 4.58 GiB (4.89 BPW) \n",
            "llm_load_print_meta: general.name     = Meta Llama 3.1 8b Bnb 4bit\n",
            "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
            "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
            "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
            "llm_load_print_meta: EOM token        = 128008 '<|eom_id|>'\n",
            "llm_load_print_meta: PAD token        = 128004 '<|finetune_right_pad_id|>'\n",
            "llm_load_print_meta: LF token         = 128 'Ä'\n",
            "llm_load_print_meta: EOG token        = 128001 '<|end_of_text|>'\n",
            "llm_load_print_meta: EOG token        = 128008 '<|eom_id|>'\n",
            "llm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\n",
            "llm_load_print_meta: max token length = 256\n",
            "llm_load_tensors: tensor 'token_embd.weight' (q4_K) (and 322 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "llm_load_tensors:   CPU_Mapped model buffer size =  4685.30 MiB\n",
            "........................................................................................\n",
            "llama_new_context_with_model: n_seq_max     = 1\n",
            "llama_new_context_with_model: n_ctx         = 512\n",
            "llama_new_context_with_model: n_ctx_per_seq = 512\n",
            "llama_new_context_with_model: n_batch       = 512\n",
            "llama_new_context_with_model: n_ubatch      = 512\n",
            "llama_new_context_with_model: flash_attn    = 0\n",
            "llama_new_context_with_model: freq_base     = 500000.0\n",
            "llama_new_context_with_model: freq_scale    = 1\n",
            "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
            "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =   258.50 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | AMX_INT8 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '15', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '500000.000000', 'general.architecture': 'llama', 'tokenizer.ggml.padding_token_id': '128004', 'general.basename': 'meta-llama-3.1', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Meta Llama 3.1 8b Bnb 4bit', 'general.organization': 'Unsloth', 'general.finetune': 'bnb-4bit', 'general.type': 'model', 'general.size_label': '8B', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh penggunaan untuk menghasilkan teks\n",
        "instruction = \"Tulis artikel singkat tentang manfaat kecerdasan buatan (AI).\"\n",
        "input_data = \"Tuliskan dengan gaya bahasa yang mudah dipahami oleh orang awam.\"\n",
        "\n",
        "# Format prompt untuk model\n",
        "prompt = f\"Di bawah ini adalah instruksi yang menjelaskan tugas, dipasangkan dengan masukan yang memberikan konteks lebih lanjut. Tulis tanggapan yang melengkapi permintaan dengan tepat.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_data}\\n\\n### Response:\\n\"\n",
        "\n",
        "# Generate response using the model\n",
        "response = llm.create_chat_completion(\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        ")\n",
        "\n",
        "# Menampilkan hasil respons dari model\n",
        "response_text = response['choices'][0]['message']['content']\n",
        "print(response_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TUEqdtXUfIl",
        "outputId": "44e164bb-8b41-4cf9-9ce1-50e7c98a2720"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =   47007.10 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   105 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /   406 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  444288.67 ms /   511 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kecerdasan buatan (AI) adalah teknologi yang terus berkembang yang memungkinkan mesin melakukan tugas-tugas yang biasanya memerlukan kecerdasan manusia.  AI dapat membantu kita dalam berbagai cara, termasuk meningkatkan efisiensi, mengurangi kesalahan, dan memberikan wawasan yang berharga.  Berikut adalah beberapa manfaat utama AI:\n",
            "\n",
            " 1. Efisiensi: AI dapat membantu bisnis dan organisasi meningkatkan efisiensi dengan mengotomatisasi tugas-tugas yang berulang.  Misalnya, AI dapat digunakan untuk mengotomatiskan proses seperti penagihan, pemrosesan data, dan analisis.  Hal ini dapat menghemat waktu dan sumber daya, memungkinkan bisnis untuk fokus pada tugas-tugas yang lebih penting.\n",
            "\n",
            " 2. Akurasi: AI dapat membantu mengurangi kesalahan dengan mengotomatiskan tugas-tugas yang berulang.  Misalnya, AI dapat digunakan untuk memeriksa dokumen, mengidentifikasi kesalahan, dan mengoreksi kesalahan.  Hal ini dapat membantu bisnis dan organisasi untuk meningkatkan kualitas produk dan layanan mereka.\n",
            "\n",
            " 3. Wawasan: AI dapat membantu bisnis dan organisasi untuk mengumpulkan dan menganalisis data dalam jumlah besar.  Hal ini dapat memberikan wawasan yang berharga tentang perilaku pelanggan, tren pasar, dan faktor lain yang dapat membantu bisnis membuat keputusan yang lebih baik.\n",
            "\n",
            " 4. Peningkatan pengalaman pelanggan: AI dapat membantu bisnis dan organisasi untuk meningkatkan pengalaman pelanggan dengan memberikan layanan yang dipersonalisasi dan respons yang cepat.  Misalnya, AI\n"
          ]
        }
      ]
    }
  ]
}